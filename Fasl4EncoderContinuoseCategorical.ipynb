{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jerVbLfD81pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8bc428-726f-4ca4-e0df-13a9e9c82549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[92276, 93510, 93446, 92880, 94501, 91901, 92677, 94531, 96019, 85255, 92021, 85266, 93111, 81524, 95220, 92802, 85262, 62234, 62214, 98021, 85377, 91752, 60002, 81418, 62025, 92253, 60016, 92692, 90265, 62034, 62088, 91915, 94565, 95008, 90803, 90038, 93314, 93720, 93924, 92040, 90211, 94568, 92543, 62249, 85331, 93105, 60046, 36372, 81521]\n",
            "[100, 60, 54, 49, 41, 32, 26, 22, 12, 12, 11, 11, 11, 11, 10, 9, 9, 7, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "(289, 3)\n",
            "(73, 3)\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "(289, 7)\n",
            "(289, 10)\n",
            "(73, 10)\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "[-0.00216541 -0.04708977  0.0634664  -0.06610923 -0.0002863  -0.00295073\n",
            "  0.05513504 -0.00325816  0.0138258   0.03955316]\n",
            "mape: 0.32\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "###Tarif Dataset\n",
        "def load_house_attributes (inputPath):\n",
        "  cols= [\"bedroom\", \"bathroom\", \"area\", \"ZipCode\", \"Price\"]\n",
        "  df=pd.read_csv(inputPath, sep= \" \", header=None, names=cols)\n",
        "  zipcodes=df[\"ZipCode\"].value_counts()\n",
        "  zipcodes=df[\"ZipCode\"].value_counts().keys().to_list()\n",
        "  counts=df[\"ZipCode\"].value_counts().to_list()\n",
        "  print(zipcodes)\n",
        "  print(counts)\n",
        "  ###Hazf Zipcode haye ba tedad <25\n",
        "  for (zipcode, count) in zip (zipcodes, counts):\n",
        "    if count<25:\n",
        "      indx=df[df[\"ZipCode\"]==zipcode].index\n",
        "      df.drop(indx, inplace=True)\n",
        "  return df\n",
        "###Normal Kardan Vizhegi haye Continuouse:\n",
        "def preprocessing_house_attribute (train, test):\n",
        "  continuous= [\"bedroom\", \"bathroom\", \"area\"]\n",
        "  sc=StandardScaler()\n",
        "  trainContinuous=sc.fit_transform(train[continuous])\n",
        "  testContinuous=sc.transform(test[continuous])\n",
        "  print(trainContinuous.shape)\n",
        "  print(testContinuous.shape)\n",
        "  ###OneHotEncoder dar ZipCode(Categorial):\n",
        "  encoder=OneHotEncoder(sparse=False)\n",
        "  trainCategorial=encoder.fit_transform(np.array(train[\"ZipCode\"]).reshape(-1,1))\n",
        "  testCategorial=encoder.transform(np.array(test[\"ZipCode\"]).reshape(-1,1))\n",
        "  print(trainCategorial)\n",
        "  print(trainCategorial.shape)\n",
        "  trainX=np.hstack([trainCategorial, trainContinuous])\n",
        "  testX=np.hstack([testCategorial, testContinuous])\n",
        "  print(trainX.shape)\n",
        "  print(testX.shape)\n",
        "  print(trainCategorial)\n",
        "  return trainX, testX\n",
        "\n",
        "###Farakhani File\n",
        "df=load_house_attributes (\"/content/drive/MyDrive/HousesInfo.txt\")\n",
        "###Normal Kardan Label\n",
        "train, test=train_test_split(df,test_size=0.2, random_state=42)\n",
        "maxPrice=train[\"Price\"].max()\n",
        "trainX, testX= preprocessing_house_attribute(train, test)\n",
        "trainY=train[\"Price\"]/maxPrice\n",
        "testY=test[\"Price\"]/maxPrice\n",
        "\n",
        "###Model Karan dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model=LinearRegression()\n",
        "model.fit(trainX, trainY)\n",
        "print(model.coef_)\n",
        "\n",
        "###Peyda kardan Deghat \n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "preds= model.predict(testX)\n",
        "mape= mean_absolute_percentage_error (testY, preds)\n",
        "print(\"mape: {:.2f}\".format(mape))\n"
      ]
    }
  ]
}